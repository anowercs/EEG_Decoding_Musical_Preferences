======================================================================
OVERFITTING DETECTION AND ANALYSIS
======================================================================
ğŸ“‚ Loading data from: /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/eeg_features_full_synthetic.pkl
ğŸ”¬ TESTING: Synthetic data (may have overfitting)
âœ… Matplotlib test successful: /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/overfitting_matplotlib_test.png
âœ… Data loaded: 657 samples, 417 features

ğŸ”§ Preparing data for overfitting analysis...
ğŸ“Š Class distribution:
   Dislike (1): 213 samples (32.4%)
   Medium (3): 225 samples (34.2%)
   Like (5): 219 samples (33.3%)
   Selected 40 features
   Data scaled using RobustScaler

â±ï¸ Starting overfitting analysis...

ğŸ” METHOD 1: TRAIN-TEST PERFORMANCE GAP
--------------------------------------------------

ğŸ¤– Analyzing Random Forest...
   Train Accuracy: 1.000
   Test Accuracy:  0.576
   Gap:            0.424
   ğŸš¨ HIGH OVERFITTING RISK (gap > 10%)

ğŸ¤– Analyzing Extra Trees...
   Train Accuracy: 1.000
   Test Accuracy:  0.659
   Gap:            0.341
   ğŸš¨ HIGH OVERFITTING RISK (gap > 10%)

ğŸ¤– Analyzing SVM...
   Train Accuracy: 0.966
   Test Accuracy:  0.652
   Gap:            0.314
   ğŸš¨ HIGH OVERFITTING RISK (gap > 10%)

ğŸ” METHOD 2: CROSS-VALIDATION STABILITY
--------------------------------------------------

ğŸ¤– Cross-validating Random Forest...
   CV Scores: ['0.553', '0.538', '0.481', '0.702', '0.695']
   Mean CV:   0.594
   Std CV:    0.089
   âš ï¸  MODERATE VARIANCE (std 5-10%)

ğŸ¤– Cross-validating Extra Trees...
   CV Scores: ['0.583', '0.583', '0.489', '0.756', '0.679']
   Mean CV:   0.618
   Std CV:    0.092
   âš ï¸  MODERATE VARIANCE (std 5-10%)

ğŸ¤– Cross-validating SVM...
   CV Scores: ['0.538', '0.591', '0.458', '0.740', '0.672']
   Mean CV:   0.600
   Std CV:    0.099
   âš ï¸  MODERATE VARIANCE (std 5-10%)

ğŸ” METHOD 3: LEARNING CURVES ANALYSIS
--------------------------------------------------

ğŸ¤– Learning curve for Random Forest...
   Final train-val gap: 0.390
   ğŸš¨ OVERFITTING: Large final gap

ğŸ¤– Learning curve for Extra Trees...
   Final train-val gap: 0.391
   ğŸš¨ OVERFITTING: Large final gap

ğŸ¤– Learning curve for SVM...
   Final train-val gap: 0.360
   ğŸš¨ OVERFITTING: Large final gap
âœ… Learning curves saved to: /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/over_fitting_learning_curves_analysis.png

ğŸ” METHOD 4: VALIDATION CURVES (Random Forest)
--------------------------------------------------
Analyzing n_estimators parameter...
âœ… Validation curve saved to: /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/over_fitting_validation_curve_Random Forest_n_estimators.png
   Optimal n_estimators: 100
   Best validation score: 0.613
   Maximum train-val gap: 0.402
   ğŸš¨ HIGH OVERFITTING across parameter range

ğŸ” METHOD 5: SUBJECT-WISE OVERFITTING
--------------------------------------------------
Analyzing 20 subjects...

======================================================================
COMPREHENSIVE OVERFITTING ANALYSIS REPORT
======================================================================

ğŸ” TRAIN-TEST GAP ANALYSIS:
   Random Forest        | Gap: 0.424 | ğŸš¨ HIGH
   Extra Trees          | Gap: 0.341 | ğŸš¨ HIGH
   SVM                  | Gap: 0.314 | ğŸš¨ HIGH

ğŸ” CROSS-VALIDATION STABILITY:
   Random Forest        | Std: 0.089 | âš ï¸ MOD VAR
   Extra Trees          | Std: 0.092 | âš ï¸ MOD VAR
   SVM                  | Std: 0.099 | âš ï¸ MOD VAR

ğŸ’¡ OVERFITTING RECOMMENDATIONS:
   â€¢ If HIGH overfitting detected:
     - Reduce model complexity (fewer trees, lower depth)
     - Use more regularization
     - Increase training data
     - Apply dropout or early stopping
   â€¢ If MODERATE overfitting:
     - Monitor validation performance
     - Consider ensemble methods
   â€¢ If LOW overfitting:
     - Current model is well-regularized
     - Consider increasing complexity for better performance

âœ… Overfitting analysis complete!
ğŸ“Š Generated plots:
   - /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/learning_curves_analysis.png
   - /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/validation_curve_Random Forest_n_estimators.png

ğŸ” To check if plots exist, run:
   ls -la /home/anower/All/Python/Thesis_VS_code/full_epoch/emon/*.png

ğŸ’¡ To test original data, change the path in main() function:
   features_path = '/home/anower/All/Python/Thesis_VS_code/full_epoch/Figure/eeg_features_full.pkl'

